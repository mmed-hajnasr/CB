{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_chunk = \"\"\"\n",
    "Chères lectrices, chers lecteurs,\n",
    "Depuis sa fondation en 2001, l'ISI s'est constamment adapté aux évolutions des besoins des formations d'ingénieurs, notamment dans le domaine de l'informatique et de ses applications. Au cours de la dernière décennie, nous avons constaté une augmentation significative des demandes d'admission émanant d'étudiants souhaitant rejoindre nos programmes. Cette tendance positive témoigne de l'intérêt croissant des jeunes talents pour nos cursus.\n",
    "Soucieux d'innover et de répondre à une diversité de besoins en formation, l'ISI accorde une attention particulière à l'employabilité de ses diplômés et à l'égalité des chances dans l'accès à ses formations. Dans cette perspective, nous prévoyons d'intensifier nos efforts afin d'attirer des candidats de qualité et de sélectionner les meilleurs profils.\n",
    "Dans une politique de rayonnement, nous nous engageons à renforcer nos partenariats avec des acteurs nationaux et internationaux, qu'ils soient du milieu académique ou industriel. Nous incitons également notre conseil scientifique à établir des collaborations étroites avec nos partenaires socio-économiques.\n",
    "\n",
    "Conscients de l'importance du développement pédagogique de notre corps enseignant, nous veillons à leur fournir les ressources nécessaires, que ce soit sur le plan matériel, numérique ou financier. Par ailleurs, nous nous efforçons d'évaluer et d'améliorer le niveau de satisfaction des étudiants, des enseignants et du personnel dans toutes nos activités pédagogiques, culturelles et organisationnelles. Dans cette optique, nous avons lancé une campagne de sensibilisation pour promouvoir notre démarche qualité et nous conformer aux normes internationales, notamment en mettant en place un système de management pour les organismes d'éducation selon la norme ISO 21001.\n",
    "Malgré notre envergure, avec près de 1600 étudiants, nous assumons pleinement notre responsabilité envers tous nos étudiants et les parties prenantes en :\n",
    "- Offrant une formation adaptée aux exigences du marché de l'emploi et aux besoins spécifiques.\n",
    "- Respectant les droits de propriété intellectuelle et la vie privée, tout en intégrant nos responsabilités sociales et environnementales ainsi que les besoins spécifiques en matière de formation.\n",
    "- Proposant un cadre propice à une vie étudiante épanouissante sur les plans culturel, sportif et associatif.\n",
    "Au nom de tous mes collègues et de l'administration, je tiens à exprimer ma profonde gratitude envers toutes les personnes qui ont contribué, par leur temps et leurs idées, à rehausser le prestige de l'ISI à travers divers projets, que ce soit en matière d'organisation, par la mise en place d'un système SMOE ISO 21001, d'accréditation selon le label CTI-EUR-ACE ou encore par notre participation à des projets nationaux et internationaux.  Nous croyons fermement que notre institution progressera davantage en favorisant une gouvernance transparente et inclusive, qui renforce la coopération, la coordination et la communication.  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "pdf_files = glob.glob(os.path.join(current_directory, 'data/*.pdf'))\n",
    "csv_files = glob.glob(os.path.join(current_directory, 'data/*.csv'))\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    with open(pdf_file, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        num_pages = len(reader.pages)\n",
    "        text = \"\"\n",
    "        for page_num in range(num_pages):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "        context = {}\n",
    "        for key in reader.metadata:\n",
    "            if key in [\"Author\",\"CreationDate\",\"Title\"]:\n",
    "                context[key]= reader.metadata[key];\n",
    "        context[\"source\"]= file    \n",
    "        return (str(context),text)\n",
    "\n",
    "text_dict = {}\n",
    "for pdf_file in pdf_files:\n",
    "    (key,text) = extract_text_from_pdf(pdf_file)\n",
    "    text_dict[key] = text\n",
    "for csv_file in csv_files:\n",
    "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
    "        text_dict[{\"source\":csv_file }] = file.read()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1744095"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "\n",
    "def remove_newlines_without_uppercase(text):\n",
    "    # Regular expression to match \\n followed by a non-uppercase letter or end of string\n",
    "    return re.sub(r'\\n(?![A-Z])', '', text)\n",
    "\n",
    "def chunkerize(raw):\n",
    "    # Convert each item in the list to a string\n",
    "    converted = [remove_newlines_without_uppercase(str(item)) for item in raw]\n",
    "\n",
    "    # Join all items with a double newline\n",
    "    text_to_chunk = \"\".join(converted)\n",
    "\n",
    "    # Define the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=50,\n",
    "        separators=[\n",
    "            \"\\n\\n\",\n",
    "            \"\\n\",\n",
    "            \".\",\n",
    "            \",\",\n",
    "            \"-\",\n",
    "            \" \",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Use the text splitter on the combined string\n",
    "    return text_splitter.split_text(text_to_chunk)\n",
    "\n",
    "for file_name in text_dict:\n",
    "    text_dict[file_name] = chunkerize(text_dict[file_name])\n",
    "\n",
    "open(\"output.txt\", \"w\").write(str(text_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
